#! /bin/sh

LOCALMONGO=true

logdb()
{
  if $LOCALMONGO ; then
    timestamp=`date`
    mongo snapdb --eval "db.harvestlog.insert({timestamp:\"$timestamp\", category:\"$1\", message:\"$2\"})"
  fi
}

log()
{
  echo $1
  echo "`date +"%b %d %T"` $1" >> import.log
  logdb info $1
}

logerror()
{
  echo $1
  echo "`date +"%b %d %T"` $1" >> error.log
  logdb error $1 
}  

error_exit()
{
  log "error: $2 (check error.log)"
  exit ${1:-1}
}

log started

# currently not necessary since writing to local mongo
#[ -n "$APIUSER" ] || error_exit 1 "APIUSER environment variable not set"
#[ -n "$APIPASS" ] || error_exit 1 "APIPASS environment variable not set"
#[ -n "$APIHOST" ] || error_exit 1 "APIHOST environment variable not set"

log "downloading snap data"
curl -O --fail --silent --show-error  www.snapretailerlocator.com/export/Nationwide.zip 2>> error.log || error_exit 1 "curl failed"

log "extracting data"
unzip -o Nationwide.zip 2>> error.log || error_exit 1 "unzip failed" 
csv=`ls store_locations*.csv`

# slice off header row or mongo will either use those names instead of
# the provided ones or else will insert as a documenting, depending on
# presence of --headerline
# tail =n +2 "$csv"

log "importing data to mongo"
FIELDS="storeName,longitude,latitude,address1,address2,city,state,zip5,zip4,county"
#mongoimport -u $APIUSER -p $APIPASS --host $APIHOST --db snapdb --collection stores --fields $FIELDS --type csv --drop < $csv 2>> error.log || error_exit 1 "mongo import failed"

mongoimport --host localhost --db snapdb --collection stores --fields $FIELDS --type csv --drop < $csv 2>> error.log || error_exit 1 "mongo import failed"

# kludge to remove the header inserted as first document
# could search for "Store_Name" but this way will work for any header
if $LOCALMONGO ; then
  mongo snapdb --eval "var id = db.stores.find().limit(1).next()._id; db.stores.remove({_id:id})"
fi

log finished

# always cleanup
trap "rm -f *.zip *.csv" EXIT
